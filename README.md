# Snake DQN - Juego de Snake con Aprendizaje por Refuerzo Profundo

Este proyecto implementa el clÃ¡sico juego de Snake utilizando Deep Q-Learning (DQN) para entrenar un agente que aprende a jugar de forma autÃ³noma. El sistema ahora solo incluye la versiÃ³n animada, eliminando modos visuales alternativos, pantalla de inicio y configuraciones visuales avanzadas.

## ğŸ’« CaracterÃ­sticas Principales

- **VersiÃ³n Animada Ãšnica**: El juego siempre inicia en modo animado, sin selecciÃ³n de modos ni configuraciones visuales adicionales.
- **Interfaz GrÃ¡fica Limpia**: DiseÃ±o simplificado, solo con los elementos necesarios para el entrenamiento y visualizaciÃ³n animada.
- **Sistema de Pathfinding**: Algoritmos A* y bÃºsqueda de caminos largos para evitar bloqueos.
- **AnÃ¡lisis Detallado**: Seguimiento y visualizaciÃ³n de mÃ©tricas de entrenamiento.

## ğŸ’» Requisitos TÃ©cnicos

- Python 3.7 o superior
- Dependencias principales:
  - PyGame >= 2.0.0 (motor del juego)
  - PyTorch >= 1.7.0 (framework de aprendizaje profundo)
  - NumPy >= 1.19.0 (procesamiento numÃ©rico)
  - Pandas >= 1.1.0 (anÃ¡lisis de datos)
  - Matplotlib >= 3.3.0 y Seaborn >= 0.11.0 (visualizaciÃ³n)

## ğŸ“ InstalaciÃ³n

### OpciÃ³n 1: InstalaciÃ³n EstÃ¡ndar

1. Clona este repositorio:

   ```bash
   git clone https://github.com/tu-usuario/snake-dqn.git
   cd snake-dqn
   ```

2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

### OpciÃ³n 2: Usando un Entorno Virtual (Recomendado)

1. Clona el repositorio y crea un entorno virtual:

   ```bash
   git clone https://github.com/tu-usuario/snake-dqn.git
   cd snake-dqn
   python -m venv venv
   ```

2. Activa el entorno virtual:

   - En Windows:
     ```bash
     venv\Scripts\activate
     ```
   - En macOS/Linux:
     ```bash
     source venv/bin/activate
     ```

3. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ® Uso

### Iniciar el Entrenamiento

Para comenzar el entrenamiento del agente:

```bash
python main.py
```

### Controles Durante el Entrenamiento

- **P**: Activa/desactiva el sistema de pathfinding.
- **S**: Cambia el tamaÃ±o de la ventana (pequeÃ±o, mediano, grande).

### Limpiar Archivos Temporales

Para eliminar archivos de cachÃ© y temporales:

```bash
python clean.py
```

## ğŸ“Š Seguimiento del Entrenamiento

Durante el entrenamiento, el sistema genera:

- **GrÃ¡ficos de Progreso**: VisualizaciÃ³n de puntuaciones y recompensas.
- **Archivos CSV**: Datos detallados para anÃ¡lisis posterior.
- **Modelos Guardados**: Puntos de control del entrenamiento.

Los resultados se guardan en las carpetas `plots/` y `results/`.

## ğŸ“‚ Estructura del Proyecto

```
snake_dqn/
â”œâ”€â”€ assets/            # Recursos visuales
â”‚   â”œâ”€â”€ apple.png      # Imagen de la manzana
â”‚   â”œâ”€â”€ arial.ttf      # Fuente usada en la interfaz
â”œâ”€â”€ src/               # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ agent.py       # Agente de aprendizaje
â”‚   â”œâ”€â”€ game.py        # ImplementaciÃ³n del juego (solo animado)
â”‚   â”œâ”€â”€ model.py       # Arquitectura de la red neuronal
â”‚   â”œâ”€â”€ shared_data.py # ParÃ¡metros compartidos
â”‚   â”œâ”€â”€ stats_manager.py # GestiÃ³n centralizada de estadÃ­sticas
â”œâ”€â”€ utils/             # Utilidades y herramientas
â”‚   â”œâ”€â”€ config.py      # ConfiguraciÃ³n general (solo animaciÃ³n)
â”‚   â”œâ”€â”€ advanced_pathfinding.py  # Algoritmos de bÃºsqueda
â”‚   â”œâ”€â”€ efficient_memory.py      # GestiÃ³n optimizada de memoria
â”‚   â”œâ”€â”€ evaluation.py            # Herramientas de evaluaciÃ³n
â”‚   â””â”€â”€ helper.py                # Funciones auxiliares
â”œâ”€â”€ clean.py           # Script para limpiar archivos temporales
â”œâ”€â”€ inspection.py       # Herramientas de inspecciÃ³n y anÃ¡lisis
â”œâ”€â”€ main.py            # Punto de entrada principal
â”œâ”€â”€ requirements.txt    # Dependencias del proyecto
â””â”€â”€ README.md          # Este archivo
```

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros del Sistema

Puedes modificar los parÃ¡metros del juego y del entrenamiento en `utils/config.py`:

- **ParÃ¡metros de Juego**: TamaÃ±o de bloque, velocidad, dimensiones.
- **HiperparÃ¡metros de DQN**: Tasa de aprendizaje, factor de descuento, tamaÃ±o de lote.
- **ParÃ¡metros de ExploraciÃ³n**: Temperatura, decaimiento, fases de exploraciÃ³n.
- **GestiÃ³n de Memoria**: TamaÃ±o del bÃºfer, umbrales de poda.

## ğŸ’¡ Algoritmos Implementados

### Deep Q-Network (DQN)

El proyecto implementa varias mejoras sobre el algoritmo DQN bÃ¡sico:

- **Double DQN**: Reduce la sobreestimaciÃ³n de valores Q utilizando una red objetivo.
- **Prioritized Experience Replay**: Muestrea experiencias mÃ¡s importantes con mayor frecuencia.
- **ExploraciÃ³n Adaptativa**: Ajusta dinÃ¡micamente la exploraciÃ³n segÃºn el progreso.

### Pathfinding

- **Algoritmo A\***: Encuentra el camino mÃ¡s corto hacia la comida.
- **BÃºsqueda de Caminos Largos**: Evita situaciones de bloqueo en serpientes largas.
- **AnÃ¡lisis de Espacio Libre**: Toma decisiones estratÃ©gicas basadas en el espacio disponible.

## ğŸ“ˆ Rendimiento

El sistema incluye herramientas para monitorear y analizar el rendimiento:

- **Seguimiento de MÃ©tricas**: PuntuaciÃ³n, longitud, recompensa, pÃ©rdida.
- **Alertas AutomÃ¡ticas**: Detecta problemas potenciales durante el entrenamiento.
- **EvaluaciÃ³n PeriÃ³dica**: Prueba el rendimiento del agente en escenarios controlados.

## ğŸ“‚ Panel de EstadÃ­sticas: IntegraciÃ³n, Cobertura y Pruebas

### Arquitectura y Funcionamiento

El **panel de estadÃ­sticas** estÃ¡ gestionado por la clase `StatsManager`, que centraliza la recolecciÃ³n, actualizaciÃ³n y notificaciÃ³n de cambios en las mÃ©tricas del juego y del agente. El panel se refresca de manera eficiente gracias a un sistema de eventos y un dirty flag, asegurando que solo se actualice cuando hay cambios reales en los datos.

#### MÃ©tricas cubiertas:
- **BÃ¡sicas:** PuntuaciÃ³n, RÃ©cord, Pasos
- **Eficiencia:** Ratio de eficiencia, Pasos por comida
- **Acciones:** Recto %, Derecha %, Izquierda %
- **Entrenamiento:** Recompensa media, Ãšltimo rÃ©cord (juego)
- **Modelo:** PÃ©rdida, Temperatura, Learning rate, Pathfinding, Modo de explotaciÃ³n

#### Flujo de integraciÃ³n
1. El juego y el agente actualizan sus mÃ©tricas internas.
2. `StatsManager` detecta cualquier cambio relevante (comparaciÃ³n profunda por categorÃ­a).
3. Si hay cambios, activa el dirty flag y notifica a la UI mediante el sistema de eventos.
4. El panel de estadÃ­sticas se refresca solo cuando el dirty flag estÃ¡ activo, mostrando siempre la informaciÃ³n mÃ¡s reciente y precisa.

### Pruebas Unitarias y de IntegraciÃ³n

El archivo `test_stats_event_system.py` incluye **tests exhaustivos** para cada grupo de mÃ©tricas y para la integraciÃ³n completa del panel:
- Cada test verifica que el valor mostrado en el panel corresponde al valor actualizado en el juego o el agente.
- Se comprueba que el dirty flag y la notificaciÃ³n de eventos funcionan correctamente.
- El test de integraciÃ³n simula el ciclo completo: actualizaciÃ³n de mÃ©trica, refresco del panel y verificaciÃ³n de la visualizaciÃ³n.

#### EjecuciÃ³n de las pruebas

Para validar que todo el panel y el sistema de eventos funcionan correctamente:

```bash
python -m unittest test_stats_event_system.py
```

Si todos los tests pasan (`OK`), puedes estar seguro de que la integraciÃ³n entre el panel, el sistema de eventos y el backend es robusta y funcional.

### ValidaciÃ³n manual en la interfaz

1. Ejecuta el juego normalmente:
   ```bash
   python main.py
   ```
2. Observa el panel de estadÃ­sticas: cada vez que cambies una mÃ©trica (por ejemplo, al superar un rÃ©cord), el valor debe actualizarse automÃ¡ticamente y sin retrasos.
3. Si detectas un valor incorrecto, ejecuta nuevamente los tests para aislar el problema.

---

**Â¡Con esta arquitectura y cobertura de pruebas, puedes confiar en la precisiÃ³n y eficiencia del panel de estadÃ­sticas, tanto a nivel interno como visual!**

## ğŸ“ DocumentaciÃ³n Adicional

Para mÃ¡s detalles sobre la arquitectura y el diseÃ±o del sistema, consulta los archivos en la carpeta `docs/`:

- [Arquitectura del Sistema](docs/architecture.md)
- [Manual de Usuario](docs/user_manual.md)

## ğŸ’¬ Contribuciones

Las contribuciones son bienvenidas. Si deseas contribuir:

1. Haz un fork del repositorio
2. Crea una rama para tu funcionalidad (`git checkout -b feature/nueva-funcionalidad`)
3. Realiza tus cambios y haz commit (`git commit -m 'AÃ±adir nueva funcionalidad'`)
4. Sube los cambios a tu fork (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ”’ Licencia

Este proyecto estÃ¡ licenciado bajo la [Licencia MIT](LICENSE).

## ğŸ‘¨â€ğŸ’» Autor

Desarrollado como parte de un proyecto de investigaciÃ³n en aprendizaje por refuerzo.

---

<p align="center">
  <i>"La inteligencia artificial es la nueva electricidad." - Andrew Ng</i>
</p>
